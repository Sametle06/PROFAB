{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROFAB is a benchmarking platform that is expected to fill the gap of datasets about protein functions with total 7656 datasets. In addition to protein function datasets, ProFAB provides complete sets of preprocessing-training-evaluation triangle to speed up machine learning usage in biological studies. Since the workflow is dense, an easy to implement user case is prepared. Here, user dataset importing is shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ProFAB provides users to import their datasets that are not available in ProFAB. To import data, SelfGet() function will be savior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.import_dataset import SelfGet\n",
    "data = SelfGet(delimiter = '\\t', name = False, label = False).get_data(file_name = \"sample.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of parameters is available in \"import_dataset\" section. With these functions, users can manage dataset \n",
    "construction. If s/he has positive set of any term available in ProFAB, only negative set can be obtained by setting \n",
    "parameter 'label' = 'negative'. For example, let's say user has positive set for EC number 1-2-7 and wants to get\n",
    "negative set to use in prediction, following lines can be executed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.import_dataset import SelfGet, ECNO\n",
    "negative_set = ECNO(label = 'negative').get_data('ecNo_1-2-7')\n",
    "positive_set = SelfGet().get_data('users_1-2-7_positive_set.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading datasets, preprocessing step comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing is applicable in three sections which are featurization, splitting and scaling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Featurization is used to convert protein fasta file into numearical feature data with many protein descriptors. Detailed \n",
    "explanation can be found in \"model_preprocess\". This function is only applicable with LINUX and MAC operation systems and input file format must be '.fasta'. Following lines can be run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.model_preprocess import extracter\n",
    "extract_protein_feature('edp', 1, \n",
    "                       'directory_folder_input_file', \n",
    "                       'sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this function, a new file that holds numerical features of proteins will be formed and it can be imported via SelfGet() function as shown in previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another preprocessing module is splitting module that is to prepare train, validation (if needed) and test sets\n",
    "for prediction. Detailed information is available in \"model_preprocess\" and reading it is highly recommended to see how function is working. If one has X (feature matrix) and y\n",
    "(label matrix), by defining fraction of test set, splitting can be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.model_preprocess import ttv_split\n",
    "X_train,X_test,y_train,y_test = ttv_split(X,y,ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than giving all data, user can choose to feed 'ttv_split' function with positive and negative sets and s/he can be obtain splitted data, eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.model_preprocess import ttv_split\n",
    "X_train,X_test,y_train,y_test = ttv_split(X_pos,X_neg,ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data is regression tasked, then y (label matrix) must be given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling is a function to rearange the range of inputs points. The reason to do it prevent imbalance problem. If data \n",
    "is stable then this function is unnecessary to apply. like other preprocessing steps, its detailed introduction can \n",
    "found in 'model_preprocess'. A use case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.model_preprocess import scale_methods\n",
    "X_train,scaler = scale_methods(X_train,scale_type = 'standard')\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling function returns fitted train (X_train) data and fitting model (scaler) to transform other sets as can be seen in use case. The rest is exactly the same as 'test_file_1'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROFAB can train any type of data. It provides both classification and regression training. Since our datasets are based on classication of proteins, as an example, classification method will be shown.\n",
    "\n",
    "After training session, outcome of training can be stored in 'model_path' ```if path is not None```. Because this process lasts to long, saving the outcome will be time-saver. Stored model must be exported and be imported with 'pickle' a python based package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.model_learn import classification_methods\n",
    "\n",
    "#Let's define model path where training model will be saved.\n",
    "model_path = 'model_path.txt'\n",
    "\n",
    "model = classification_methods(ml_type = 'logistic_reg',\n",
    "                                X_train = X_train,\n",
    "                                y_train = y_train,\n",
    "                                path = model_path\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training session is done, evaluation can be done with following lines of code. The output of evaluation is given below of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Get Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.model_evaluate import evaluate_score\n",
    "\n",
    "score_train,f_train = evaluate_score(model,X_train,y_train,preds = True)\n",
    "score_test,f_test = evaluate_score(model,X_test,y_test,preds = True)\n",
    "score_validation,f_validation = evaluate_score(model,X_validation,y_validation,preds = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of train and test are given for data: 'ecNo_1-2-7 'target'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Table Formating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data in table format, a dictionary that consists of scores of different sets must be given. Following lines of code can be executed to tabularize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If user wants to see result in a table, following codes can be run:\n",
    "from profab.model_evaluate import form_table\n",
    "\n",
    "score_path = 'score_path.csv' #To save the results.\n",
    "\n",
    "scores = {'train':score_train,'test':score_test,'validation':score_validation}\n",
    "\n",
    "#form_table() function will write scores to score_path.\n",
    "form_table(scores = scores, path = score_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Working with Multiple Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If user wants to make a prediction uses multiple class, ProFAB can handle this with 'for-loop'. For this case, let's say user has positive and negative datasets for 2 GO terms which names of files are:\n",
    "\n",
    "    - GO_0000018_negative_data.txt\n",
    "    - GO_0019935_negative_data.txt\n",
    "    - GO_0000018_positive_data.txt\n",
    "    - GO_0019935_positive_data.txt\n",
    "\n",
    "Both files are tab separated and protein features are described with their name.\n",
    "So, this time using SelfGet() function with parameter 'name' = True will be efficient to load negative datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=49.50251256281407, gamma=0.0517947467923121, kernel='linear',\n",
      "    max_iter=2500)\n",
      "SVC(C=49.50251256281407, gamma=0.0517947467923121, kernel='linear',\n",
      "    max_iter=2500)\n"
     ]
    }
   ],
   "source": [
    "from profab.import_dataset import GOID, SelfGet\n",
    "from profab.model_preprocess import ttv_split\n",
    "from profab.model_learn import classification_methods\n",
    "from profab.model_evaluate import evaluate_score, multiple_form_table\n",
    "\n",
    "#GO_List: variable includes GO terms\n",
    "GO_list = ['GO_0000018','GO_0019935']\n",
    "\n",
    "#To hold scores of model performances\n",
    "scores = {}\n",
    "\n",
    "for go_term in GO_list: \n",
    "\n",
    "    #User imports his/her negative and positive datasets with SelfGet() function\n",
    "    negative_data_name = go_term + '_negative_data.txt'\n",
    "    negative_set = SelfGet(name = True).get_data(file_name = negative_data_name)\n",
    "    positive_data_name = go_term + '_positive_data.txt'\n",
    "    positive_set = SelfGet(name = True).get_data(file_name = positive_data_name)\n",
    "    \n",
    "    #splitting\n",
    "    X_train,X_test,X_validation,y_train,y_test,y_validation = ttv_split(X_pos = positive_set,\n",
    "                                                              X_neg = negative_set,\n",
    "                                                              ratio = [0.1,0.2])\n",
    "    #prediction\n",
    "    model = classification_methods(ml_type = 'SVM',\n",
    "                                  X_train = X_train,\n",
    "                                  X_valid = X_validation,\n",
    "                                  y_train = y_train,\n",
    "                                  y_valid = y_validation)\n",
    "    \n",
    "    #evaluation\n",
    "    score_train = evaluate_score(model,X_train,y_train) \n",
    "    score_test = evaluate_score(model,X_test,y_test)\n",
    "    set_scores = {'train':score_train,'test': score_test}\n",
    "    scores.update({go_term:set_scores})\n",
    "\n",
    "#tabularizing the scores\n",
    "score_path = 'score_path.csv'\n",
    "multiple_form_table(scores, score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GO_0000018': {'train': {'Precision': 0.680365296803653, 'Recall': 0.4257142857142857, 'F1-Score': 0.523725834797891, 'F05-Score': 0.6076672104404568, 'Accuracy': 0.7426400759734093, 'MCC': 0.37854022684114785, 'AUC': 0.6630705141231458, 'AUPRC': 0.6484813867005648, 'TP': 149, 'FP': 70, 'TN': 633, 'FN': 201}, 'test': {'Precision': 0.7352941176470589, 'Recall': 0.49019607843137253, 'F1-Score': 0.588235294117647, 'F05-Score': 0.6684491978609626, 'Accuracy': 0.7682119205298014, 'MCC': 0.4531328287625726, 'AUC': 0.7000980392156864, 'AUPRC': 0.6988378132710038, 'TP': 25, 'FP': 9, 'TN': 91, 'FN': 26}}, 'GO_0019935': {'train': {'Precision': 0.765661252900232, 'Recall': 0.6043956043956044, 'F1-Score': 0.67553735926305, 'F05-Score': 0.7268722466960352, 'Accuracy': 0.8022457891453525, 'MCC': 0.543894233191604, 'AUC': 0.7544210756131287, 'AUPRC': 0.7524021030084921, 'TP': 330, 'FP': 101, 'TN': 956, 'FN': 216}, 'test': {'Precision': 0.775, 'Recall': 0.49206349206349204, 'F1-Score': 0.6019417475728155, 'F05-Score': 0.695067264573991, 'Accuracy': 0.8217391304347826, 'MCC': 0.5155438600770936, 'AUC': 0.719085638247315, 'AUPRC': 0.7030969634230503, 'TP': 31, 'FP': 9, 'TN': 158, 'FN': 32}}}\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
