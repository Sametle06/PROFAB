{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROFAB is a benchmarking platform that is expected to fill the gap of datasets about protein functions with total 7656 datasets. In addition to protein function datasets, ProFAB provides complete sets of preprocessing-training-evaluation triangle to speed up machine learning usage in biological studies. Since the workflow is dense, an easy to implement user case is prepared. This use case is to show functions to import data available in ProFAB only and their applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ProFAB allows users to import datasets ready to use in training algorithms from ProFAB database with a few lines of code.To import data from ProFAB database, following three lines will do the job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.import_dataset import ECNO\n",
    "data_model = ECNO(ratio = [0.1, 0.2], protein_feature = 'paac', pre_determined = False, set_type = 'random')\n",
    "X_train,X_test,X_validation,y_train,y_test,y_validation = data_model.get_data(data_name = 'ecNo_1-2-4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of parameters is available in section of \"import_dataset\". Above code is to import datasets for Enzyme comission number 1-2-4 with three sets which are train, validation and test sets. Similar code is used to import any GO term data. An example code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.import_dataset import GOID\n",
    "data_model = GOID(ratio = [0.1, 0.2], protein_feature = 'paac', pre_determined = False, set_type = 'random')\n",
    "X_train,X_test,X_validation,y_train,y_test,y_validation = data_model.get_data(data_name = 'GO_0000018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading datasets, preprocessing step comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing is applicable in three sections which are featurization, splitting and scaling. However, since ProFAB provides datasets with splitted and numerical features automatically, featurization and splitting steps will be explained only in 'test_file_2'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling is a function to rearange the range of inputs points. The reason to do it prevent imbalance problem. If data \n",
    "is stable then this function is unnecessary to apply. like other preprocessing steps, its detailed introduction can \n",
    "found in 'model_preprocess'. A use case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.model_preprocess import scale_methods\n",
    "X_train,scaler = scale_methods(X_train,scale_type = 'standard')\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling function returns fitted train (X_train) data and fitting model (scaler) to transform other sets as can be seen in use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROFAB can train any type of data. It provides both classification and regression training. Since our datasets are based on classication of proteins, as an example, classification method will be shown.\n",
    "\n",
    "After training session, outcome of training can be stored in 'model_path' ```if path is not None```. Because this process lasts to long, saving the outcome will be time-saver. Stored model must be exported and be imported with 'pickle' a python based package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.model_learn import classification_methods\n",
    "\n",
    "#Let's define model path where training model will be saved.\n",
    "model_path = 'model_path.txt'\n",
    "\n",
    "model = classification_methods(ml_type = 'logistic_reg',\n",
    "                                X_train = X_train,\n",
    "                                y_train = y_train,\n",
    "                                path = model_path\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training session is done, evaluation can be done with following lines of code. The output of evaluation is given below of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Get Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.model_evaluate import evaluate_score\n",
    "\n",
    "score_train,f_train = evaluate_score(model,X_train,y_train,preds = True)\n",
    "score_test,f_test = evaluate_score(model,X_test,y_test,preds = True)\n",
    "score_validation,f_validation = evaluate_score(model,X_validation,y_validation,preds = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of train and test are given for data: 'ecNo_1-2-7 'target'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Table Formating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data in table format, a dictionary that consists of scores of different sets must be given. Following lines of code can be executed to tabularize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If user wants to see all results in a table, following codes can be run:\n",
    "from profab.model_evaluate import form_table\n",
    "\n",
    "score_path = 'score_path.csv' #To save the results.\n",
    "\n",
    "scores = {'train':score_train,'test':score_test,'validation':score_validation}\n",
    "form_table(scores = scores, path = score_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'form_table' function will write scores for one dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Working with Multiple Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If user wants to predict mutliple data and see performance results, ProFAB can be handle with the 'for-loop'. Let's say, user has negative sets for 3 GO terms and import positive sets from our servers, a use case will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from profab.import_dataset import GOID, SelfGet\n",
    "from profab.model_preprocess import ttv_split\n",
    "from profab.model_learn import classification_methods\n",
    "from profab.model_evaluate import evaluate_score, multiple_form_table\n",
    "\n",
    "GO_list = ['GO_0000018','GO_0019935']\n",
    "scores = {}\n",
    "for go_term in GO_list: #GO_List: variable includes GO terms\n",
    "    \n",
    "    #Importing data\n",
    "    negative_data_name = go_term + '_negative_data.txt' \n",
    "    #This file is given as sample. Please consider dimension matching while importing data.\n",
    "    \n",
    "    negative_set = SelfGet(name = True).get_data(file_name = negative_data_name)\n",
    "    positive_set = GOID(set_type = 'random', protein_feature = 'aac', label = 'positive').get_data(go_term)\n",
    "    \n",
    "    print(len(negative_set[0]))\n",
    "    print(len(positive_set[0]))\n",
    "    \n",
    "    #splitting\n",
    "    X_train,X_test,X_validation,y_train,y_test,y_validation = ttv_split(X_pos = positive_set,\n",
    "                                                              X_neg = negative_set,\n",
    "                                                              ratio = [0.1,0.2])\n",
    "    #for i in range(len(X_train)):\n",
    "    #    print(len(X_train[i]))\n",
    "              \n",
    "    #prediction\n",
    "    model = classification_methods(ml_type = 'SVM',\n",
    "                                  X_train = X_train,\n",
    "                                  X_valid = X_validation,\n",
    "                                  y_train = y_train,\n",
    "                                  y_valid = y_validation)\n",
    "    \n",
    "    #evaluation\n",
    "    score_train = evaluate_score(model,X_train,y_train) \n",
    "    score_test = evaluate_score(model,X_test,y_test)\n",
    "    set_scores = {'train':score_train,'test': score_test}\n",
    "    scores.update({go_term:set_scores})\n",
    "\n",
    "#tabularizing the scores\n",
    "score_path = 'score_path.csv'\n",
    "multiple_form_table(scores, score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
