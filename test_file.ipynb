{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROFAB is a benchmarking platform that provides dataset, classifies the proteins according functional annotations and evaluates the training models. The reason to do this platform is providing complete sets of dataset-training-evaluation triangle. Since the workflow is dense, an easy to implement user case is prepared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import data in Python, following lines of code can be used. It is designed as easy to implement and if user needs to import multiple dataset at the sametime a loop can be used. For example following codes can be examined:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To import single dataset from ecNo prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from profab.import_dataset import ECNO\n",
    "data_model = ECNO(ratio = 0.2, protein_feature = 'paac', pre_determined = True, set_type = 'similarity')\n",
    "X_train,X_test,X_validation,y_train,y_test,y_validation = data_model.get_data(data_name = 'ecNo_1-2-7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To import multiple dataset from ecNo prediction data in a loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROFAB can train any type of data. It provides both classification and regression training. Since our datasets are based on classication of proteins, as an example, classification method will be shown, however, the same process is valid for regression, too (only training algorithms are different in name).\n",
    "\n",
    "After training session, outcome of training can be stored in 'model_path' ```if path != None```. Because this process lasts to long, saving the outcome will be time-saver. Stored model must be exported and be imported with 'pickle' Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=67.67709090909092, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=1000, multi_class='ovr', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#To train the data:\n",
    "import pickle\n",
    "from profab.model_process import scale_methods, classification_methods\n",
    "\n",
    "#Let's define model path where training model will be saved.\n",
    "model_path = 'model_path.txt'\n",
    "\n",
    "#Then sets are scaled to eleminate bias. Scaler is obtained from train data and can be used for different sets\n",
    "X_train,scaler = scale_methods(X_train,scale_type = 'standard')\n",
    "X_test,X_validation = scaler.transform(X_test),scaler.transform(X_validation)\n",
    "\n",
    "#After assigning paths and scaling datasets, training can be done manually like this way (validation by hand):\n",
    "model = classification_methods(ml_type = 'logistic_reg',\n",
    "                                X_train = X_train,\n",
    "                                y_train = y_train,\n",
    "                                X_valid = X_validation,\n",
    "                                y_valid = y_validation,\n",
    "                                path = model_path\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training session is done, evaluation can be done with following lines of code. The output of evaluation is given below of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#by returning model, it can be directly used or\n",
    "#saved model can be obtained by using 'pickle' package.\n",
    "model = pickle.load(open(model_path,'rb'))\n",
    "\n",
    "from profab.model_evaluate import evaluate_score\n",
    "\n",
    "score_train,f_train = evaluate_score(model,X_train,y_train,preds = True)\n",
    "score_test,f_test = evaluate_score(model,X_test,y_test,preds = True)\n",
    "score_validation,f_validation = evaluate_score(model,X_validation,y_validation,preds = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of train and test are given for data: 'ecNo_1-2-7 'target'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.868421052631579, 'Recall': 0.75, 'F1-Score': 0.8048780487804879, 'F05-Score': 0.8418367346938777, 'Accuracy': 0.9166666666666666, 'MCC': 0.7555256046223662, 'AUC': 0.8581081081081082, 'AUPRC': 0.8378563596491229, 'TP': 33, 'FP': 5, 'TN': 143, 'FN': 11}\n"
     ]
    }
   ],
   "source": [
    "print(score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.8, 'Recall': 0.6666666666666666, 'F1-Score': 0.7272727272727272, 'F05-Score': 0.7692307692307692, 'Accuracy': 0.875, 'MCC': 0.6515837655350015, 'AUC': 0.8055555555555555, 'AUPRC': 0.775, 'TP': 4, 'FP': 1, 'TN': 17, 'FN': 2}\n"
     ]
    }
   ],
   "source": [
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Precision': 0.8823529411764706, 'Recall': 0.8823529411764706, 'F1-Score': 0.8823529411764706, 'F05-Score': 0.8823529411764706, 'Accuracy': 0.9183673469387755, 'MCC': 0.8198529411764706, 'AUC': 0.9099264705882353, 'AUPRC': 0.9027611044417767, 'TP': 15, 'FP': 2, 'TN': 30, 'FN': 2}\n"
     ]
    }
   ],
   "source": [
    "print(score_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Formating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data in table format, following lines of code can be executed. Besides scores, sizes of each sets are also given. Tables is stored in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If user wants to see all results in a table, following codes can be run:\n",
    "from profab.model_evaluate import form_table\n",
    "\n",
    "score_path = 'score_path.csv' #To save the results.\n",
    "\n",
    "scores = {'train':score_train,'test':score_test,'validation':score_validation}\n",
    "form_table(scores = scores, path = score_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
